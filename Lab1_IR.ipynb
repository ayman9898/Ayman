{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ayman Abdullah\n",
    "\n",
    "3700039\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.16.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting genism\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement genism (from versions: none)\n",
      "ERROR: No matching distribution found for genism\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade genism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gensim) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gensim) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gensim) (1.16.5)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.24.0)\n",
      "Requirement already satisfied: boto in c:\\users\\dell\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (1.14.56)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.56 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (1.17.56)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from botocore<1.18.0,>=1.17.56->boto3->smart-open>=1.7.0->gensim) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from botocore<1.18.0,>=1.17.56->boto3->smart-open>=1.7.0->gensim) (0.15.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.0\n"
     ]
    }
   ],
   "source": [
    "import gensim as gs\n",
    "print(gs.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence= \"Tokenization is the process of breaking down text document apart into those pieces\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'computer', 'science', 'artificialintelligence', 'AI', 'sometimes', 'called', 'machineintelligence', 'is', 'intelligence', 'demonstrated', 'bymachines', 'in', 'contrast', 'to', 'the', 'natural', 'intelligencedisplayed', 'by', 'humans', 'and', 'animals', 'Computer', 'sciencedefines', 'AI', 'research', 'as', 'the', 'study', 'of', 'intelligentagents', 'any', 'device', 'that', 'perceives', 'its', 'environment', 'andtakes', 'actions', 'that', 'maximize', 'its', 'chance', 'of', 'successfullyachieving', 'its', 'goals']\n"
     ]
    }
   ],
   "source": [
    "import gensim as gs \n",
    "tokenizedWord=list(gs.utils.tokenize(Sentence))\n",
    "print(tokenizedWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function tokenize in module gensim.utils:\n",
      "\n",
      "tokenize(text, lowercase=False, deacc=False, encoding='utf8', errors='strict', to_lower=False, lower=False)\n",
      "    Iteratively yield tokens as unicode strings, optionally removing accent marks and lowercasing it.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    text : str or bytes\n",
      "        Input string.\n",
      "    deacc : bool, optional\n",
      "        Remove accentuation using :func:`~gensim.utils.deaccent`?\n",
      "    encoding : str, optional\n",
      "        Encoding of input string, used as parameter for :func:`~gensim.utils.to_unicode`.\n",
      "    errors : str, optional\n",
      "        Error handling behaviour, used as parameter for :func:`~gensim.utils.to_unicode`.\n",
      "    lowercase : bool, optional\n",
      "        Lowercase the input string?\n",
      "    to_lower : bool, optional\n",
      "        Same as `lowercase`. Convenience alias.\n",
      "    lower : bool, optional\n",
      "        Same as `lowercase`. Convenience alias.\n",
      "    \n",
      "    Yields\n",
      "    ------\n",
      "    str\n",
      "        Contiguous sequences of alphabetic characters (no digits!), using :func:`~gensim.utils.simple_tokenize`\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    .. sourcecode:: pycon\n",
      "    \n",
      "        >>> from gensim.utils import tokenize\n",
      "        >>> list(tokenize('Nic nemůže letět rychlostí vyšší, než 300 tisíc kilometrů za sekundu!', deacc=True))\n",
      "        [u'Nic', u'nemuze', u'letet', u'rychlosti', u'vyssi', u'nez', u'tisic', u'kilometru', u'za', u'sekundu']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 2: Tokenize the following sentence and write down the obtain! \n",
    "gs.utils.tokenize\n",
    "help(gs.utils.tokenize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence= \"In computer science, artificialintelligence (AI), sometimes called machineintelligence, is intelligence demonstrated bymachines, in contrast to the natural intelligencedisplayed by humans and animals. Computer sciencedefines AI research as the study of intelligentagents: any device that perceives its environment andtakes actions that maximize its chance of successfullyachieving its goals.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokenization',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'breaking',\n",
       " 'down',\n",
       " 'text',\n",
       " 'documentapart',\n",
       " 'into',\n",
       " 'those',\n",
       " 'pieces']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentence= ''' Tokenization is the process of breaking down\n",
    "text documentapart into those pieces'''\n",
    "import gensim as gs\n",
    "tokenizedWord= list(gs.utils.tokenize(Sentence))\n",
    "tokenizedWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 3), (26, 1), (27, 1), (28, 1), (29, 3), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 2), (44, 2), (45, 1)]]\n"
     ]
    }
   ],
   "source": [
    "#Exercise 3: Count frequency of each word. \n",
    "document = ''' In computer science, artificial\n",
    "intelligence (AI), sometimes called machine\n",
    "intelligence, is intelligence demonstrated by\n",
    "machines, in contrast to the natural intelligence\n",
    "displayed by humans and animals. Computer science\n",
    "defines AI research as the study of intelligent\n",
    "agents: any device that perceives its environment and\n",
    "takes actions that maximize its chance of successfully\n",
    "achieving its goals.”\n",
    "'''\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "text = [document]\n",
    "tokens = [[token for token in sentence.split()] for sentence\n",
    "in text]\n",
    "gensim_dictionary = corpora.Dictionary()\n",
    "gensim_corpus = [gensim_dictionary.doc2bow(token,\n",
    "allow_update=True) for token in tokens]\n",
    "print(gensim_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('(AI),', 1), ('AI', 1), ('Computer', 1), ('In', 1), ('achieving', 1), ('actions', 1), ('agents:', 1), ('and', 2), ('animals.', 1), ('any', 1), ('artificial', 1), ('as', 1), ('by', 2), ('called', 1), ('chance', 1), ('computer', 1), ('contrast', 1), ('defines', 1), ('demonstrated', 1), ('device', 1), ('displayed', 1), ('environment', 1), ('goals.”', 1), ('humans', 1), ('in', 1), ('intelligence', 3), ('intelligence,', 1), ('intelligent', 1), ('is', 1), ('its', 3), ('machine', 1), ('machines,', 1), ('maximize', 1), ('natural', 1), ('of', 2), ('perceives', 1), ('research', 1), ('science', 1), ('science,', 1), ('sometimes', 1), ('study', 1), ('successfully', 1), ('takes', 1), ('that', 2), ('the', 2), ('to', 1)]]\n"
     ]
    }
   ],
   "source": [
    "word_frequencies = [[(gensim_dictionary[id], frequence) for id, frequence in couple] for couple in gensim_corpus]\n",
    "print(word_frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What do you see?\n",
    "#Notice that some words are repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import \n",
    "simple_preprocess\n",
    "from smart_open import smart_open\n",
    "import os\n",
    "\n",
    "tokens = [simple_preprocess(sentence, deacc=True) for sentence in open(r'C:\\filetext.txt', encoding='utf-8')]\n",
    "\n",
    "gensim_dictionary = corpora.Dictionary()\n",
    "gensim_corpus = [gensim_dictionary.doc2bow(token, allow_update=True) for token in tokens]\n",
    "word_frequencies = [[(gensim_dictionary[id], frequence) for id, frequence in couple] for couple in gensim_corpus]\n",
    "\n",
    "print(word_frequencies)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
