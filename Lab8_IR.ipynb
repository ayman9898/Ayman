{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ayman Abdullah\n",
    "#370039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: num2words in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.5.10)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from num2words) (0.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "\n",
    "import nltk \n",
    "import os \n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 1: Explore content of files. Write your code below. \n",
    "title = \"used files\"\n",
    "os.chdir(r'C:\\mini_newsgroups\\comp.graphics')\n",
    "paths = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(str(os.getcwd())+'/'+title+'/'):\n",
    "    for i in filenames:\n",
    "        paths.append(str(dirpath)+str(\"\\\\\")+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\mini_newsgroups\\\\comp.graphics/used files/\\\\37916'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!gatech!asuvax!cs.utexas.edu!zaphod.mps.ohio-state.edu!saimiri.primate.wisc.edu!usenet.coe.montana.edu!news.u.washington.edu!uw-beaver!cs.ubc.ca!unixg.ubc.ca!kakwa.ucs.ualberta.ca!ersys!joth\n",
      "From: joth@ersys.edmonton.ab.ca (Joe Tham)\n",
      "Newsgroups: comp.graphics\n",
      "Subject: Where can I find SIPP?\n",
      "Message-ID: <yFXJ2B2w165w@ersys.edmonton.ab.ca>\n",
      "Date: Mon, 05 Apr 93 14:58:21 MDT\n",
      "Organization: Edmonton Remote Systems #2, Edmonton, AB, Canada\n",
      "Lines: 11\n",
      "\n",
      "        I recently got a file describing a library of rendering routines \n",
      "called SIPP (SImple Polygon Processor).  Could anyone tell me where I can \n",
      "FTP the source code and which is the newest version around?\n",
      "        Also, I've never used Renderman so I was wondering if Renderman \n",
      "is like SIPP?  ie. a library of rendering routines which one uses to make \n",
      "a program that creates the image...\n",
      "\n",
      "                                        Thanks,  Joe Tham\n",
      "\n",
      "--\n",
      "Joe Tham              joth@ersys.edmonton.ab.ca \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file1 = open(paths[0])\n",
    "print(file1.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\mini_newsgroups\\comp.graphics/used files//37916\n",
      "C:\\mini_newsgroups\\comp.graphics/used files//37921\n",
      "C:\\mini_newsgroups\\comp.graphics/used files//37930\n",
      "C:\\mini_newsgroups\\comp.graphics/used files//37936\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filenames)):\n",
    "    print(dirpath+'/'+filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 2: Do the necessary data preparation (Similar towhat did you do in the lab 06, You also need to remove stop words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stop words \n",
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return np.char.strip(new_text) \n",
    "\n",
    "#Removing punctuation\n",
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \" \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data \n",
    "\n",
    "#Convert to lowercase\n",
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)\n",
    "\n",
    "#Stemming\n",
    "def stemming(data):\n",
    "    stemmer= PorterStemmer()\n",
    "\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\n",
    "    return np.char.strip(new_text) \n",
    "\n",
    "#Converting numbers to its equivalent words \n",
    "def convert_numbers(data):\n",
    "    data = np.char.replace(data, \"0\", \" zero \")\n",
    "    data = np.char.replace(data, \"1\", \" one \")\n",
    "    data = np.char.replace(data, \"2\", \" two \")\n",
    "    data = np.char.replace(data, \"3\", \" three \")\n",
    "    data = np.char.replace(data, \"4\", \" four \")\n",
    "    data = np.char.replace(data, \"5\", \" five \")\n",
    "    data = np.char.replace(data, \"6\", \" six \")\n",
    "    data = np.char.replace(data, \"7\", \" seven \")\n",
    "    data = np.char.replace(data, \"8\", \" eight \")\n",
    "    data = np.char.replace(data, \"9\", \" nine \")\n",
    "    return data \n",
    "\n",
    "#Removing header \n",
    "def remove_header(data):\n",
    "    try:\n",
    "        ind = data.index('\\n\\n')\n",
    "        data = data[ind:]\n",
    "    except:\n",
    "        print(\"No Header\")\n",
    "    return data \n",
    "\n",
    "#Removing apostrophe \n",
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\") \n",
    "\n",
    "#Removing single characters \n",
    "def remove_single_characters(data):\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return np.char.strip(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = remove_header(data) \n",
    "    data = convert_lower_case(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = remove_punctuation(data)\n",
    "    data = remove_stop_words(data)\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_single_characters(data)\n",
    "    data = stemming(data)\n",
    "         \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['recent', 'got', 'file', 'describ', 'librari', 'render', 'routin', 'call', 'sipp', 'simpl', 'polygon', 'processor', 'could', 'anyon', 'tell', 'ftp', 'sourc', 'code', 'newest', 'version', 'around', 'also', 've', 'never', 'use', 'renderman', 'wonder', 'renderman', 'like', 'sipp', 'ie', 'librari', 'render', 'routin', 'one', 'use', 'make', 'program', 'creat', 'imag', 'thank', 'joe', 'tham', 'joe', 'tham', 'joth', 'ersi', 'edmonton', 'ab', 'ca']]\n",
      "[['recent', 'got', 'file', 'describ', 'librari', 'render', 'routin', 'call', 'sipp', 'simpl', 'polygon', 'processor', 'could', 'anyon', 'tell', 'ftp', 'sourc', 'code', 'newest', 'version', 'around', 'also', 've', 'never', 'use', 'renderman', 'wonder', 'renderman', 'like', 'sipp', 'ie', 'librari', 'render', 'routin', 'one', 'use', 'make', 'program', 'creat', 'imag', 'thank', 'joe', 'tham', 'joe', 'tham', 'joth', 'ersi', 'edmonton', 'ab', 'ca'], ['hello', 'everybodi', 'use', 'pixar', 'renderman', 'three', 'scene', 'descript', 'languag', 'creat', 'three', 'world', 'pleas', 'help', 'use', 'renderman', 'librari', 'next', 'document', 'nextstep', 'version', 'renderman', 'avail', 'creat', 'complic', 'scene', 'render', 'use', 'surfac', 'shader', 'bring', 'life', 'appli', 'shadow', 'reflect', 'far', 'understand', 'defin', 'environment', 'shadow', 'map', 'produc', 'reflect', 'shadow', 'know', 'use', 'advis', 'simpl', 'rib', 'exampl', 'appreci', 'thank', 'advanc', 'alex', 'kolesov', 'moscow', 'russia', 'talu', 'imag', 'commun', 'corpor', 'mail', 'alex', 'talu', 'msk', 'su', 'next', 'mail', 'accept']]\n",
      "[['recent', 'got', 'file', 'describ', 'librari', 'render', 'routin', 'call', 'sipp', 'simpl', 'polygon', 'processor', 'could', 'anyon', 'tell', 'ftp', 'sourc', 'code', 'newest', 'version', 'around', 'also', 've', 'never', 'use', 'renderman', 'wonder', 'renderman', 'like', 'sipp', 'ie', 'librari', 'render', 'routin', 'one', 'use', 'make', 'program', 'creat', 'imag', 'thank', 'joe', 'tham', 'joe', 'tham', 'joth', 'ersi', 'edmonton', 'ab', 'ca'], ['hello', 'everybodi', 'use', 'pixar', 'renderman', 'three', 'scene', 'descript', 'languag', 'creat', 'three', 'world', 'pleas', 'help', 'use', 'renderman', 'librari', 'next', 'document', 'nextstep', 'version', 'renderman', 'avail', 'creat', 'complic', 'scene', 'render', 'use', 'surfac', 'shader', 'bring', 'life', 'appli', 'shadow', 'reflect', 'far', 'understand', 'defin', 'environment', 'shadow', 'map', 'produc', 'reflect', 'shadow', 'know', 'use', 'advis', 'simpl', 'rib', 'exampl', 'appreci', 'thank', 'advanc', 'alex', 'kolesov', 'moscow', 'russia', 'talu', 'imag', 'commun', 'corpor', 'mail', 'alex', 'talu', 'msk', 'su', 'next', 'mail', 'accept'], ['anybodi', 'know', 'good', 'two', 'graphic', 'packag', 'avail', 'ibm', 'rs', 'six', 'zero', 'zero', 'zero', 'aix', 'look', 'someth', 'like', 'dec', 'gk', 'hewlett', 'packard', 'starbas', 'reason', 'good', 'support', 'differ', 'output', 'devic', 'like', 'plotter', 'termin', 'etc', 'tri', 'also', 'xgk', 'one', 'one', 'distribut', 'ibm', 'implement', 'phig', 'work', 'requir', 'output', 'devic', 'window', 'salesman', 'ibm', 'familiar', 'graphic', 'expect', 'good', 'solut', 'ari', 'ari', 'suutari', 'ari', 'carel', 'fi', 'carelcomp', 'oy', 'lappeenranta', 'finland']]\n",
      "[['recent', 'got', 'file', 'describ', 'librari', 'render', 'routin', 'call', 'sipp', 'simpl', 'polygon', 'processor', 'could', 'anyon', 'tell', 'ftp', 'sourc', 'code', 'newest', 'version', 'around', 'also', 've', 'never', 'use', 'renderman', 'wonder', 'renderman', 'like', 'sipp', 'ie', 'librari', 'render', 'routin', 'one', 'use', 'make', 'program', 'creat', 'imag', 'thank', 'joe', 'tham', 'joe', 'tham', 'joth', 'ersi', 'edmonton', 'ab', 'ca'], ['hello', 'everybodi', 'use', 'pixar', 'renderman', 'three', 'scene', 'descript', 'languag', 'creat', 'three', 'world', 'pleas', 'help', 'use', 'renderman', 'librari', 'next', 'document', 'nextstep', 'version', 'renderman', 'avail', 'creat', 'complic', 'scene', 'render', 'use', 'surfac', 'shader', 'bring', 'life', 'appli', 'shadow', 'reflect', 'far', 'understand', 'defin', 'environment', 'shadow', 'map', 'produc', 'reflect', 'shadow', 'know', 'use', 'advis', 'simpl', 'rib', 'exampl', 'appreci', 'thank', 'advanc', 'alex', 'kolesov', 'moscow', 'russia', 'talu', 'imag', 'commun', 'corpor', 'mail', 'alex', 'talu', 'msk', 'su', 'next', 'mail', 'accept'], ['anybodi', 'know', 'good', 'two', 'graphic', 'packag', 'avail', 'ibm', 'rs', 'six', 'zero', 'zero', 'zero', 'aix', 'look', 'someth', 'like', 'dec', 'gk', 'hewlett', 'packard', 'starbas', 'reason', 'good', 'support', 'differ', 'output', 'devic', 'like', 'plotter', 'termin', 'etc', 'tri', 'also', 'xgk', 'one', 'one', 'distribut', 'ibm', 'implement', 'phig', 'work', 'requir', 'output', 'devic', 'window', 'salesman', 'ibm', 'familiar', 'graphic', 'expect', 'good', 'solut', 'ari', 'ari', 'suutari', 'ari', 'carel', 'fi', 'carelcomp', 'oy', 'lappeenranta', 'finland'], ['requir', 'bgi', 'driver', 'super', 'vga', 'display', 'super', 'xvga', 'display', 'anyon', 'know', 'could', 'obtain', 'relev', 'driver', 'ftp', 'site', 'regard', 'simon', 'crow']]\n"
     ]
    }
   ],
   "source": [
    "processed_text = []\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    file = open(dirpath+'/'+filenames[i],'r', encoding='cp1250')\n",
    "    text = file.read().strip()\n",
    "    file.close()\n",
    "    \n",
    "    processed_text.append(word_tokenize(str(preprocess(text))))\n",
    "    print(processed_text)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = {}\n",
    "N= len(processed_text)\n",
    "\n",
    "for i in range(N):\n",
    "    tokens = processed_text[i]\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w]={i}\n",
    "        except:\n",
    "            DF[w]={i}\n",
    "            \n",
    "for i in DF:\n",
    "    DF[i]= len(DF[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recent': 1,\n",
       " 'got': 1,\n",
       " 'file': 1,\n",
       " 'describ': 1,\n",
       " 'librari': 1,\n",
       " 'render': 1,\n",
       " 'routin': 1,\n",
       " 'call': 1,\n",
       " 'sipp': 1,\n",
       " 'simpl': 1,\n",
       " 'polygon': 1,\n",
       " 'processor': 1,\n",
       " 'could': 1,\n",
       " 'anyon': 1,\n",
       " 'tell': 1,\n",
       " 'ftp': 1,\n",
       " 'sourc': 1,\n",
       " 'code': 1,\n",
       " 'newest': 1,\n",
       " 'version': 1,\n",
       " 'around': 1,\n",
       " 'also': 1,\n",
       " 've': 1,\n",
       " 'never': 1,\n",
       " 'use': 1,\n",
       " 'renderman': 1,\n",
       " 'wonder': 1,\n",
       " 'like': 1,\n",
       " 'ie': 1,\n",
       " 'one': 1,\n",
       " 'make': 1,\n",
       " 'program': 1,\n",
       " 'creat': 1,\n",
       " 'imag': 1,\n",
       " 'thank': 1,\n",
       " 'joe': 1,\n",
       " 'tham': 1,\n",
       " 'joth': 1,\n",
       " 'ersi': 1,\n",
       " 'edmonton': 1,\n",
       " 'ab': 1,\n",
       " 'ca': 1,\n",
       " 'hello': 1,\n",
       " 'everybodi': 1,\n",
       " 'pixar': 1,\n",
       " 'three': 1,\n",
       " 'scene': 1,\n",
       " 'descript': 1,\n",
       " 'languag': 1,\n",
       " 'world': 1,\n",
       " 'pleas': 1,\n",
       " 'help': 1,\n",
       " 'next': 1,\n",
       " 'document': 1,\n",
       " 'nextstep': 1,\n",
       " 'avail': 1,\n",
       " 'complic': 1,\n",
       " 'surfac': 1,\n",
       " 'shader': 1,\n",
       " 'bring': 1,\n",
       " 'life': 1,\n",
       " 'appli': 1,\n",
       " 'shadow': 1,\n",
       " 'reflect': 1,\n",
       " 'far': 1,\n",
       " 'understand': 1,\n",
       " 'defin': 1,\n",
       " 'environment': 1,\n",
       " 'map': 1,\n",
       " 'produc': 1,\n",
       " 'know': 1,\n",
       " 'advis': 1,\n",
       " 'rib': 1,\n",
       " 'exampl': 1,\n",
       " 'appreci': 1,\n",
       " 'advanc': 1,\n",
       " 'alex': 1,\n",
       " 'kolesov': 1,\n",
       " 'moscow': 1,\n",
       " 'russia': 1,\n",
       " 'talu': 1,\n",
       " 'commun': 1,\n",
       " 'corpor': 1,\n",
       " 'mail': 1,\n",
       " 'msk': 1,\n",
       " 'su': 1,\n",
       " 'accept': 1,\n",
       " 'anybodi': 1,\n",
       " 'good': 1,\n",
       " 'two': 1,\n",
       " 'graphic': 1,\n",
       " 'packag': 1,\n",
       " 'ibm': 1,\n",
       " 'rs': 1,\n",
       " 'six': 1,\n",
       " 'zero': 1,\n",
       " 'aix': 1,\n",
       " 'look': 1,\n",
       " 'someth': 1,\n",
       " 'dec': 1,\n",
       " 'gk': 1,\n",
       " 'hewlett': 1,\n",
       " 'packard': 1,\n",
       " 'starbas': 1,\n",
       " 'reason': 1,\n",
       " 'support': 1,\n",
       " 'differ': 1,\n",
       " 'output': 1,\n",
       " 'devic': 1,\n",
       " 'plotter': 1,\n",
       " 'termin': 1,\n",
       " 'etc': 1,\n",
       " 'tri': 1,\n",
       " 'xgk': 1,\n",
       " 'distribut': 1,\n",
       " 'implement': 1,\n",
       " 'phig': 1,\n",
       " 'work': 1,\n",
       " 'requir': 1,\n",
       " 'window': 1,\n",
       " 'salesman': 1,\n",
       " 'familiar': 1,\n",
       " 'expect': 1,\n",
       " 'solut': 1,\n",
       " 'ari': 1,\n",
       " 'suutari': 1,\n",
       " 'carel': 1,\n",
       " 'fi': 1,\n",
       " 'carelcomp': 1,\n",
       " 'oy': 1,\n",
       " 'lappeenranta': 1,\n",
       " 'finland': 1,\n",
       " 'bgi': 1,\n",
       " 'driver': 1,\n",
       " 'super': 1,\n",
       " 'vga': 1,\n",
       " 'display': 1,\n",
       " 'xvga': 1,\n",
       " 'obtain': 1,\n",
       " 'relev': 1,\n",
       " 'site': 1,\n",
       " 'regard': 1,\n",
       " 'simon': 1,\n",
       " 'crow': 1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "#Exercise 3: Calculating DF for all words found in processed_text list. Print the first five inputs \n",
    "total =len(DF)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recent', 'got', 'file', 'describ', 'librari']\n"
     ]
    }
   ],
   "source": [
    "total_v = [x for x in DF]\n",
    "print(total_v[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: good --->frequency: 1\n"
     ]
    }
   ],
   "source": [
    "def doc_freq(word):\n",
    "    c=0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c\n",
    "WORD= \"good\"\n",
    "print (\"word:\",WORD,\"--->frequency:\",doc_freq(WORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=0\n",
    "tf_idf = {}\n",
    "\n",
    "for i in range(N):\n",
    "    tokens = processed_text[i]\n",
    "    \n",
    "    counter = Counter(tokens + processed_text[i])\n",
    "    words_count = len(tokens + processed_text[i])\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        tf_idf[doc, token] = tf*idf\n",
    "        \n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 'ab'): 0.018325814637483104,\n",
       " (0, 'also'): 0.018325814637483104,\n",
       " (0, 'anyon'): 0.018325814637483104,\n",
       " (0, 'around'): 0.018325814637483104,\n",
       " (0, 'ca'): 0.018325814637483104,\n",
       " (0, 'call'): 0.018325814637483104,\n",
       " (0, 'code'): 0.018325814637483104,\n",
       " (0, 'could'): 0.018325814637483104,\n",
       " (0, 'creat'): 0.018325814637483104,\n",
       " (0, 'describ'): 0.018325814637483104,\n",
       " (0, 'edmonton'): 0.018325814637483104,\n",
       " (0, 'ersi'): 0.018325814637483104,\n",
       " (0, 'file'): 0.018325814637483104,\n",
       " (0, 'ftp'): 0.018325814637483104,\n",
       " (0, 'got'): 0.018325814637483104,\n",
       " (0, 'ie'): 0.018325814637483104,\n",
       " (0, 'imag'): 0.018325814637483104,\n",
       " (0, 'joe'): 0.03665162927496621,\n",
       " (0, 'joth'): 0.018325814637483104,\n",
       " (0, 'librari'): 0.03665162927496621,\n",
       " (0, 'like'): 0.018325814637483104,\n",
       " (0, 'make'): 0.018325814637483104,\n",
       " (0, 'never'): 0.018325814637483104,\n",
       " (0, 'newest'): 0.018325814637483104,\n",
       " (0, 'one'): 0.018325814637483104,\n",
       " (0, 'polygon'): 0.018325814637483104,\n",
       " (0, 'processor'): 0.018325814637483104,\n",
       " (0, 'program'): 0.018325814637483104,\n",
       " (0, 'recent'): 0.018325814637483104,\n",
       " (0, 'render'): 0.03665162927496621,\n",
       " (0, 'renderman'): 0.03665162927496621,\n",
       " (0, 'routin'): 0.03665162927496621,\n",
       " (0, 'simpl'): 0.018325814637483104,\n",
       " (0, 'sipp'): 0.03665162927496621,\n",
       " (0, 'sourc'): 0.018325814637483104,\n",
       " (0, 'tell'): 0.018325814637483104,\n",
       " (0, 'tham'): 0.03665162927496621,\n",
       " (0, 'thank'): 0.018325814637483104,\n",
       " (0, 'use'): 0.03665162927496621,\n",
       " (0, 've'): 0.018325814637483104,\n",
       " (0, 'version'): 0.018325814637483104,\n",
       " (0, 'wonder'): 0.018325814637483104,\n",
       " (1, 'accept'): 0.013279575824263118,\n",
       " (1, 'advanc'): 0.013279575824263118,\n",
       " (1, 'advis'): 0.013279575824263118,\n",
       " (1, 'alex'): 0.026559151648526236,\n",
       " (1, 'appli'): 0.013279575824263118,\n",
       " (1, 'appreci'): 0.013279575824263118,\n",
       " (1, 'avail'): 0.013279575824263118,\n",
       " (1, 'bring'): 0.013279575824263118,\n",
       " (1, 'commun'): 0.013279575824263118,\n",
       " (1, 'complic'): 0.013279575824263118,\n",
       " (1, 'corpor'): 0.013279575824263118,\n",
       " (1, 'creat'): 0.026559151648526236,\n",
       " (1, 'defin'): 0.013279575824263118,\n",
       " (1, 'descript'): 0.013279575824263118,\n",
       " (1, 'document'): 0.013279575824263118,\n",
       " (1, 'environment'): 0.013279575824263118,\n",
       " (1, 'everybodi'): 0.013279575824263118,\n",
       " (1, 'exampl'): 0.013279575824263118,\n",
       " (1, 'far'): 0.013279575824263118,\n",
       " (1, 'hello'): 0.013279575824263118,\n",
       " (1, 'help'): 0.013279575824263118,\n",
       " (1, 'imag'): 0.013279575824263118,\n",
       " (1, 'know'): 0.013279575824263118,\n",
       " (1, 'kolesov'): 0.013279575824263118,\n",
       " (1, 'languag'): 0.013279575824263118,\n",
       " (1, 'librari'): 0.013279575824263118,\n",
       " (1, 'life'): 0.013279575824263118,\n",
       " (1, 'mail'): 0.026559151648526236,\n",
       " (1, 'map'): 0.013279575824263118,\n",
       " (1, 'moscow'): 0.013279575824263118,\n",
       " (1, 'msk'): 0.013279575824263118,\n",
       " (1, 'next'): 0.026559151648526236,\n",
       " (1, 'nextstep'): 0.013279575824263118,\n",
       " (1, 'pixar'): 0.013279575824263118,\n",
       " (1, 'pleas'): 0.013279575824263118,\n",
       " (1, 'produc'): 0.013279575824263118,\n",
       " (1, 'reflect'): 0.026559151648526236,\n",
       " (1, 'render'): 0.013279575824263118,\n",
       " (1, 'renderman'): 0.039838727472789354,\n",
       " (1, 'rib'): 0.013279575824263118,\n",
       " (1, 'russia'): 0.013279575824263118,\n",
       " (1, 'scene'): 0.026559151648526236,\n",
       " (1, 'shader'): 0.013279575824263118,\n",
       " (1, 'shadow'): 0.039838727472789354,\n",
       " (1, 'simpl'): 0.013279575824263118,\n",
       " (1, 'su'): 0.013279575824263118,\n",
       " (1, 'surfac'): 0.013279575824263118,\n",
       " (1, 'talu'): 0.026559151648526236,\n",
       " (1, 'thank'): 0.013279575824263118,\n",
       " (1, 'three'): 0.026559151648526236,\n",
       " (1, 'understand'): 0.013279575824263118,\n",
       " (1, 'use'): 0.05311830329705247,\n",
       " (1, 'version'): 0.013279575824263118,\n",
       " (1, 'world'): 0.013279575824263118,\n",
       " (2, 'aix'): 0.014544297331335795,\n",
       " (2, 'also'): 0.014544297331335795,\n",
       " (2, 'anybodi'): 0.014544297331335795,\n",
       " (2, 'ari'): 0.04363289199400738,\n",
       " (2, 'avail'): 0.014544297331335795,\n",
       " (2, 'carel'): 0.014544297331335795,\n",
       " (2, 'carelcomp'): 0.014544297331335795,\n",
       " (2, 'dec'): 0.014544297331335795,\n",
       " (2, 'devic'): 0.02908859466267159,\n",
       " (2, 'differ'): 0.014544297331335795,\n",
       " (2, 'distribut'): 0.014544297331335795,\n",
       " (2, 'etc'): 0.014544297331335795,\n",
       " (2, 'expect'): 0.014544297331335795,\n",
       " (2, 'familiar'): 0.014544297331335795,\n",
       " (2, 'fi'): 0.014544297331335795,\n",
       " (2, 'finland'): 0.014544297331335795,\n",
       " (2, 'gk'): 0.014544297331335795,\n",
       " (2, 'good'): 0.04363289199400738,\n",
       " (2, 'graphic'): 0.02908859466267159,\n",
       " (2, 'hewlett'): 0.014544297331335795,\n",
       " (2, 'ibm'): 0.04363289199400738,\n",
       " (2, 'implement'): 0.014544297331335795,\n",
       " (2, 'know'): 0.014544297331335795,\n",
       " (2, 'lappeenranta'): 0.014544297331335795,\n",
       " (2, 'like'): 0.02908859466267159,\n",
       " (2, 'look'): 0.014544297331335795,\n",
       " (2, 'one'): 0.02908859466267159,\n",
       " (2, 'output'): 0.02908859466267159,\n",
       " (2, 'oy'): 0.014544297331335795,\n",
       " (2, 'packag'): 0.014544297331335795,\n",
       " (2, 'packard'): 0.014544297331335795,\n",
       " (2, 'phig'): 0.014544297331335795,\n",
       " (2, 'plotter'): 0.014544297331335795,\n",
       " (2, 'reason'): 0.014544297331335795,\n",
       " (2, 'requir'): 0.014544297331335795,\n",
       " (2, 'rs'): 0.014544297331335795,\n",
       " (2, 'salesman'): 0.014544297331335795,\n",
       " (2, 'six'): 0.014544297331335795,\n",
       " (2, 'solut'): 0.014544297331335795,\n",
       " (2, 'someth'): 0.014544297331335795,\n",
       " (2, 'starbas'): 0.014544297331335795,\n",
       " (2, 'support'): 0.014544297331335795,\n",
       " (2, 'suutari'): 0.014544297331335795,\n",
       " (2, 'termin'): 0.014544297331335795,\n",
       " (2, 'tri'): 0.014544297331335795,\n",
       " (2, 'two'): 0.014544297331335795,\n",
       " (2, 'window'): 0.014544297331335795,\n",
       " (2, 'work'): 0.014544297331335795,\n",
       " (2, 'xgk'): 0.014544297331335795,\n",
       " (2, 'zero'): 0.04363289199400738,\n",
       " (3, 'anyon'): 0.04581453659370776,\n",
       " (3, 'bgi'): 0.04581453659370776,\n",
       " (3, 'could'): 0.04581453659370776,\n",
       " (3, 'crow'): 0.04581453659370776,\n",
       " (3, 'display'): 0.09162907318741552,\n",
       " (3, 'driver'): 0.09162907318741552,\n",
       " (3, 'ftp'): 0.04581453659370776,\n",
       " (3, 'know'): 0.04581453659370776,\n",
       " (3, 'obtain'): 0.04581453659370776,\n",
       " (3, 'regard'): 0.04581453659370776,\n",
       " (3, 'relev'): 0.04581453659370776,\n",
       " (3, 'requir'): 0.04581453659370776,\n",
       " (3, 'simon'): 0.04581453659370776,\n",
       " (3, 'site'): 0.04581453659370776,\n",
       " (3, 'super'): 0.09162907318741552,\n",
       " (3, 'vga'): 0.04581453659370776,\n",
       " (3, 'xvga'): 0.04581453659370776}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018325814637483104"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf[(0,'also')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0, 'ab'), 0.018325814637483104)]\n"
     ]
    }
   ],
   "source": [
    "#Exercise 6. What is the TF-IDF score for the first word in the collection?\n",
    "dict_items = tf_idf.items()\n",
    "\n",
    "print(list(dict_items)[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Header\n",
      "Matching Score\n",
      "\n",
      "Query: I recently got a file describing a library\n",
      "\n",
      "['recent', 'got', 'file', 'describ', 'librari']\n",
      "\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "def matching_score(k, query):\n",
    "    preprocessed_query = preprocess(query)\n",
    "    tokens = word_tokenize(str(preprocessed_query))\n",
    "    print(\"Matching Score\")\n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"\")\n",
    "    print(tokens)\n",
    "\n",
    "    query_weights = {} \n",
    "    for key in tf_idf:\n",
    "        if key[1] in tokens:\n",
    "            try:\n",
    "                query_weights[key[0]] += tf_idf[key]\n",
    "            except:\n",
    "                query_weights[key[0]] = tf_idf[key]\n",
    "\n",
    "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"\")\n",
    "\n",
    "    l = []\n",
    "\n",
    "    for i in query_weights[:k]:\n",
    "        l.append(i[0])\n",
    "\n",
    "    print(l)\n",
    "\n",
    "matching_score(2, \"I recently got a file describing a library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 'ab'): 0.018325814637483104,\n",
       " (0, 'also'): 0.010216512475319815,\n",
       " (0, 'anyon'): 0.010216512475319815,\n",
       " (0, 'around'): 0.018325814637483104,\n",
       " (0, 'ca'): 0.018325814637483104,\n",
       " (0, 'call'): 0.018325814637483104,\n",
       " (0, 'code'): 0.018325814637483104,\n",
       " (0, 'could'): 0.010216512475319815,\n",
       " (0, 'creat'): 0.010216512475319815,\n",
       " (0, 'describ'): 0.018325814637483104,\n",
       " (0, 'edmonton'): 0.018325814637483104,\n",
       " (0, 'ersi'): 0.018325814637483104,\n",
       " (0, 'file'): 0.018325814637483104,\n",
       " (0, 'ftp'): 0.010216512475319815,\n",
       " (0, 'got'): 0.018325814637483104,\n",
       " (0, 'ie'): 0.018325814637483104,\n",
       " (0, 'imag'): 0.010216512475319815,\n",
       " (0, 'joe'): 0.03665162927496621,\n",
       " (0, 'joth'): 0.018325814637483104,\n",
       " (0, 'librari'): 0.02043302495063963,\n",
       " (0, 'like'): 0.010216512475319815,\n",
       " (0, 'make'): 0.018325814637483104,\n",
       " (0, 'never'): 0.018325814637483104,\n",
       " (0, 'newest'): 0.018325814637483104,\n",
       " (0, 'one'): 0.010216512475319815,\n",
       " (0, 'polygon'): 0.018325814637483104,\n",
       " (0, 'processor'): 0.018325814637483104,\n",
       " (0, 'program'): 0.018325814637483104,\n",
       " (0, 'recent'): 0.018325814637483104,\n",
       " (0, 'render'): 0.02043302495063963,\n",
       " (0, 'renderman'): 0.02043302495063963,\n",
       " (0, 'routin'): 0.03665162927496621,\n",
       " (0, 'simpl'): 0.010216512475319815,\n",
       " (0, 'sipp'): 0.03665162927496621,\n",
       " (0, 'sourc'): 0.018325814637483104,\n",
       " (0, 'tell'): 0.018325814637483104,\n",
       " (0, 'tham'): 0.03665162927496621,\n",
       " (0, 'thank'): 0.010216512475319815,\n",
       " (0, 'use'): 0.02043302495063963,\n",
       " (0, 've'): 0.018325814637483104,\n",
       " (0, 'version'): 0.010216512475319815,\n",
       " (0, 'wonder'): 0.018325814637483104,\n",
       " (1, 'accept'): 0.013279575824263118,\n",
       " (1, 'advanc'): 0.013279575824263118,\n",
       " (1, 'advis'): 0.013279575824263118,\n",
       " (1, 'alex'): 0.026559151648526236,\n",
       " (1, 'appli'): 0.013279575824263118,\n",
       " (1, 'appreci'): 0.013279575824263118,\n",
       " (1, 'avail'): 0.007403269909652039,\n",
       " (1, 'bring'): 0.013279575824263118,\n",
       " (1, 'commun'): 0.013279575824263118,\n",
       " (1, 'complic'): 0.013279575824263118,\n",
       " (1, 'corpor'): 0.013279575824263118,\n",
       " (1, 'creat'): 0.014806539819304078,\n",
       " (1, 'defin'): 0.013279575824263118,\n",
       " (1, 'descript'): 0.013279575824263118,\n",
       " (1, 'document'): 0.013279575824263118,\n",
       " (1, 'environment'): 0.013279575824263118,\n",
       " (1, 'everybodi'): 0.013279575824263118,\n",
       " (1, 'exampl'): 0.013279575824263118,\n",
       " (1, 'far'): 0.013279575824263118,\n",
       " (1, 'hello'): 0.013279575824263118,\n",
       " (1, 'help'): 0.013279575824263118,\n",
       " (1, 'imag'): 0.007403269909652039,\n",
       " (1, 'know'): 0.0032339645118001415,\n",
       " (1, 'kolesov'): 0.013279575824263118,\n",
       " (1, 'languag'): 0.013279575824263118,\n",
       " (1, 'librari'): 0.007403269909652039,\n",
       " (1, 'life'): 0.013279575824263118,\n",
       " (1, 'mail'): 0.026559151648526236,\n",
       " (1, 'map'): 0.013279575824263118,\n",
       " (1, 'moscow'): 0.013279575824263118,\n",
       " (1, 'msk'): 0.013279575824263118,\n",
       " (1, 'next'): 0.026559151648526236,\n",
       " (1, 'nextstep'): 0.013279575824263118,\n",
       " (1, 'pixar'): 0.013279575824263118,\n",
       " (1, 'pleas'): 0.013279575824263118,\n",
       " (1, 'produc'): 0.013279575824263118,\n",
       " (1, 'reflect'): 0.026559151648526236,\n",
       " (1, 'render'): 0.007403269909652039,\n",
       " (1, 'renderman'): 0.022209809728956118,\n",
       " (1, 'rib'): 0.013279575824263118,\n",
       " (1, 'russia'): 0.013279575824263118,\n",
       " (1, 'scene'): 0.026559151648526236,\n",
       " (1, 'shader'): 0.013279575824263118,\n",
       " (1, 'shadow'): 0.039838727472789354,\n",
       " (1, 'simpl'): 0.007403269909652039,\n",
       " (1, 'su'): 0.013279575824263118,\n",
       " (1, 'surfac'): 0.013279575824263118,\n",
       " (1, 'talu'): 0.026559151648526236,\n",
       " (1, 'thank'): 0.007403269909652039,\n",
       " (1, 'three'): 0.026559151648526236,\n",
       " (1, 'understand'): 0.013279575824263118,\n",
       " (1, 'use'): 0.029613079638608156,\n",
       " (1, 'version'): 0.007403269909652039,\n",
       " (1, 'world'): 0.013279575824263118,\n",
       " (2, 'aix'): 0.014544297331335795,\n",
       " (2, 'also'): 0.008108343234380805,\n",
       " (2, 'anybodi'): 0.014544297331335795,\n",
       " (2, 'ari'): 0.04363289199400738,\n",
       " (2, 'avail'): 0.008108343234380805,\n",
       " (2, 'carel'): 0.014544297331335795,\n",
       " (2, 'carelcomp'): 0.014544297331335795,\n",
       " (2, 'dec'): 0.014544297331335795,\n",
       " (2, 'devic'): 0.02908859466267159,\n",
       " (2, 'differ'): 0.014544297331335795,\n",
       " (2, 'distribut'): 0.014544297331335795,\n",
       " (2, 'etc'): 0.014544297331335795,\n",
       " (2, 'expect'): 0.014544297331335795,\n",
       " (2, 'familiar'): 0.014544297331335795,\n",
       " (2, 'fi'): 0.014544297331335795,\n",
       " (2, 'finland'): 0.014544297331335795,\n",
       " (2, 'gk'): 0.014544297331335795,\n",
       " (2, 'good'): 0.04363289199400738,\n",
       " (2, 'graphic'): 0.02908859466267159,\n",
       " (2, 'hewlett'): 0.014544297331335795,\n",
       " (2, 'ibm'): 0.04363289199400738,\n",
       " (2, 'implement'): 0.014544297331335795,\n",
       " (2, 'know'): 0.0035419611319715836,\n",
       " (2, 'lappeenranta'): 0.014544297331335795,\n",
       " (2, 'like'): 0.01621668646876161,\n",
       " (2, 'look'): 0.014544297331335795,\n",
       " (2, 'one'): 0.01621668646876161,\n",
       " (2, 'output'): 0.02908859466267159,\n",
       " (2, 'oy'): 0.014544297331335795,\n",
       " (2, 'packag'): 0.014544297331335795,\n",
       " (2, 'packard'): 0.014544297331335795,\n",
       " (2, 'phig'): 0.014544297331335795,\n",
       " (2, 'plotter'): 0.014544297331335795,\n",
       " (2, 'reason'): 0.014544297331335795,\n",
       " (2, 'requir'): 0.008108343234380805,\n",
       " (2, 'rs'): 0.014544297331335795,\n",
       " (2, 'salesman'): 0.014544297331335795,\n",
       " (2, 'six'): 0.014544297331335795,\n",
       " (2, 'solut'): 0.014544297331335795,\n",
       " (2, 'someth'): 0.014544297331335795,\n",
       " (2, 'starbas'): 0.014544297331335795,\n",
       " (2, 'support'): 0.014544297331335795,\n",
       " (2, 'suutari'): 0.014544297331335795,\n",
       " (2, 'termin'): 0.014544297331335795,\n",
       " (2, 'tri'): 0.014544297331335795,\n",
       " (2, 'two'): 0.014544297331335795,\n",
       " (2, 'window'): 0.014544297331335795,\n",
       " (2, 'work'): 0.014544297331335795,\n",
       " (2, 'xgk'): 0.014544297331335795,\n",
       " (2, 'zero'): 0.04363289199400738,\n",
       " (3, 'anyon'): 0.025541281188299538,\n",
       " (3, 'bgi'): 0.04581453659370776,\n",
       " (3, 'could'): 0.025541281188299538,\n",
       " (3, 'crow'): 0.04581453659370776,\n",
       " (3, 'display'): 0.09162907318741552,\n",
       " (3, 'driver'): 0.09162907318741552,\n",
       " (3, 'ftp'): 0.025541281188299538,\n",
       " (3, 'know'): 0.01115717756571049,\n",
       " (3, 'obtain'): 0.04581453659370776,\n",
       " (3, 'regard'): 0.04581453659370776,\n",
       " (3, 'relev'): 0.04581453659370776,\n",
       " (3, 'requir'): 0.025541281188299538,\n",
       " (3, 'simon'): 0.04581453659370776,\n",
       " (3, 'site'): 0.04581453659370776,\n",
       " (3, 'super'): 0.09162907318741552,\n",
       " (3, 'vga'): 0.04581453659370776,\n",
       " (3, 'xvga'): 0.04581453659370776}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Home Task\n",
    "#Exercise7 Use the whole files found in folder “comp.graphics” and compute TF-IDF for each word appears in the collection.\n",
    "title = \"comp.graphics\"\n",
    "os.chdir(r'C:\\mini_newsgroups')\n",
    "paths = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(str(os.getcwd())+'/'+title+'/'):\n",
    "    for i in filenames:\n",
    "        paths.append(str(dirpath)+str(\"\\\\\")+i) \n",
    "        \n",
    "processed_text = []\n",
    "for i in range(len(filenames)):\n",
    "    file = open(dirpath+'/'+ filenames[i], 'r', encoding='cp1250', errors='ignore')\n",
    "    text = file.read().strip()\n",
    "    file.close()\n",
    "    processed_text.append(word_tokenize(str(preprocess(text))))\n",
    "\n",
    "\n",
    "DF = {}\n",
    "N = len(processed_text)\n",
    "\n",
    "for i in range(N):\n",
    "    tokens = processed_text[i]\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "            \n",
    "for i in DF:\n",
    "    DF[i] = len(DF[i])\n",
    "\n",
    "\n",
    "doc = 0\n",
    "tf_idf = {}\n",
    "for i in range(N):\n",
    "    tokens = processed_text[i]\n",
    "    counter = Counter(tokens + processed_text[i])\n",
    "    words_count = len(tokens + processed_text[i])\n",
    "\n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        tf_idf[doc, token] = tf*idf\n",
    "        \n",
    "    doc += 1 \n",
    "\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
